{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwZJoLPlWgaqOdfv3W/bXq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","\n","class Node:\n","  def __init__(self, feature=None, threshold=None,left=None, right=None,*,value=None):\n","    self.feature = feature\n","    self.threshold = threshold\n","    self.left = left\n","    self.right = right\n","    self.value = value\n","\n","  def is_leaf_node(self):\n","    return self.value is not None\n","\n","class DecisionTree:\n","  def __init__(self,min_samples_split=2, max_depth=100, n_features = None, root=None):\n","    self.min_samples_split = min_samples_split\n","    self.max_depth = max_depth\n","    self.n_features = n_features\n","    self.root = root\n","\n","  def fit(self, X, y):\n","    self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n","    self.root = self._grow_tree(X,y)\n","\n","  def predict(self, X):\n","    return np.array([self._traverse_tree(x,self.root) for x in X])\n","\n","\n","\n","  def _traverse_tree(self,x,node):\n","    if node.is_leaf_node():\n","      return node.value\n","\n","    if x[node.feature] <= node.threshold:\n","      return self._traverse_tree(x, node.left)\n","    return self._traverse_tree(x, node.right)\n","\n","\n","\n","  def _grow_tree(self,X,y,depth=0):\n","    n_samples, n_feats = X.shape\n","    n_labels = len(np.unique(y))\n","\n","    #Stopping criteria Check.\n","    if (depth > self.max_depth or n_labels==1 or n_samples<self.min_samples_split):\n","      leaf_value = self._most_common_label(y)\n","      return Node(value=leaf_value)\n","\n","    feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n","\n","    #Best split\n","    best_feature, best_thr = self._best_split(X, y, feat_idxs)\n","\n","    #Child Nodes\n","    left_idxs, right_idxs = self._split(X[:,best_feature], best_thr)\n","    left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n","    right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n","    return Node(best_feature, best_thr, left, right)\n","\n","\n","  def _most_common_label(self,y):\n","    counter = Counter(y)\n","    value = counter.most_common(1)[0][0]\n","    return value\n","\n","  def _best_split(self, X, y, feat_idxs):\n","    best_gain=-1\n","    split_idx, split_threshold = None, None\n","\n","    for feat_idx in feat_idxs:\n","      X_column = X[:,feat_idx]\n","      thresholds = np.unique(X_column)\n","\n","      for thr in thresholds:\n","         gain = self._information_gain(y, X_column, thr)\n","\n","         if gain > best_gain:\n","          best_gain = gain\n","          split_idx = feat_idx\n","          split_threshold = thr\n","\n","    return split_idx, split_threshold\n","\n","  def _information_gain(self,y,X_column, thr):\n","    #Parent Entropy\n","    parent_entropy = self._entropy(y)\n","\n","\n","    #create Children\n","    left_idxs, right_idxs = self._split(X_column, thr) \n","    \n","    if (len(right_idxs)==0 or len(left_idxs)==0):\n","      return 0\n","\n","    #calculate child wt.avg Entropy\n","    n_l , n_r = len(left_idxs), len(right_idxs)\n","    e_l , e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n","    wt_child_entropy = (n_l/len(y)) * e_l  + (n_r/len(y)) * e_r\n","    #calculate gain\n","    return (parent_entropy - wt_child_entropy)\n","\n","  def _entropy(self, y):\n","    hist = np.bincount(y)\n","    ps = hist / len(y)\n","    return -np.sum([p*np.log(p) for p in ps if p>0])\n","\n","  def _split(self,X_column, thr):\n","    right_idxs = np.argwhere(X_column > thr).flatten()\n","    left_idxs = np.argwhere(X_column <= thr).flatten()\n","    return left_idxs, right_idxs\n"],"metadata":{"id":"xacCiL1m55z9","executionInfo":{"status":"ok","timestamp":1686043931118,"user_tz":-330,"elapsed":577,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_V9gLhW0y6Ji","executionInfo":{"status":"ok","timestamp":1686041863962,"user_tz":-330,"elapsed":1989,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"outputs":[],"source":["import numpy as np\n","from collections import Counter\n","\n","class RandomForest:\n","  def __init__(self, max_depth=10, n_features=None, min_sample_splits=2, n_trees=10):\n","    self.max_depth = max_depth\n","    self.n_features = n_features\n","    self.min_sample_splits = min_sample_splits\n","    self.n_trees = n_trees\n","    self.trees = []\n","\n","  def fit(self,X,y):\n","    self.trees = []\n","    for _ in range(self.n_trees):\n","      tree = DecisionTree(max_depth=self.max_depth,\n","                          n_features=self.n_features,\n","                          min_samples_split=self.min_sample_splits)\n","      X_sample, y_sample = self._bootstrap_samples(X,y)\n","      tree.fit(X_sample, y_sample)\n","      self.trees.append(tree)\n","\n","  def _most_common_label(self,y):\n","    value = Counter(y).most_common(1)[0][0]\n","    return value\n","\n","  def _bootstrap_samples(self,X,y):\n","    n_samples = X.shape[0]\n","    idxs = np.random.choice(n_samples, n_samples, replace=True)\n","    return X[idxs], y[idxs]\n","\n","  def predict(self,X):\n","    predictions = np.array([tree.predict(X) for tree in self.trees])\n","    tree_preds = np.swapaxes(predictions, 0, 1)\n","    predictions = np.array([self._most_common_label(pred) for pred in tree_preds])\n","    return predictions"]},{"cell_type":"code","source":["class Hyperparameter:\n","  def __init__(self,max_depth = [10], min_samples_split=[2], n_features=[], best_params=None):\n","    self.max_depth = max_depth\n","    self.min_samples_split = min_samples_split\n","    self.n_features = n_features\n","    self.best_params = best_params\n","\n","  def tune(self, X, y):\n","    best_score = 0\n","    #Splitting\n","    X_train, X_test, y_train, y_test = self._splitting(X, y)\n","\n","    #Best Score\n","    if len(self.n_features)==0 :\n","      for depth in self.max_depth:\n","        for mss in self.min_samples_split:\n","          tree = DecisionTree(max_depth=depth, min_samples_split=mss)\n","          tree.fit(X_train,y_train)\n","          y_pred = tree.predict(X_test)\n","          score = self._accuracy(y_test, y_pred)\n","          #Assigning.\n","          if score > best_score:\n","            best_params = {\"max_depth\" : depth, \"min_samples_split\" : mss}\n","    else:\n","       for depth in self.max_depth:\n","        for mss in self.min_samples_split:\n","          for n_feats in self.n_features:\n","            tree = DecisionTree(max_depth=depth, min_samples_split=mss, n_features=n_feats)\n","            tree.fit(X_train,y_train)\n","            y_pred = tree.predict(X_test)\n","            score = self._accuracy(y_test, y_pred)\n","            #Assigning.\n","            if score > best_score:\n","              best_score = score\n","              best_params = {\"max_depth\" : depth, \"min_samples_split\" : mss, \"n_features\":n_feats}\n","    return best_params, best_score\n","\n","  def _splitting(self,X, y):\n","    a , b, c, d = train_test_split(X,y, test_size=0.2, random_state=42)\n","    return a, b, c, d\n","\n","  def _accuracy(self,y_test, y_pred):\n","    return np.sum(y_test==y_pred)/len(y_test)"],"metadata":{"id":"za1Wda8mDDHl","executionInfo":{"status":"ok","timestamp":1686044227211,"user_tz":-330,"elapsed":3,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"xO9VUAWx6EJe","executionInfo":{"status":"ok","timestamp":1686044029325,"user_tz":-330,"elapsed":1574,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data = datasets.load_breast_cancer()\n","X, y = data.data, data.target"],"metadata":{"id":"Zdgfrrqv6esF","executionInfo":{"status":"ok","timestamp":1686044032239,"user_tz":-330,"elapsed":601,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"5qL5Way_6s3s","executionInfo":{"status":"ok","timestamp":1686044052088,"user_tz":-330,"elapsed":802,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHo-aAGWEnoL","executionInfo":{"status":"ok","timestamp":1686044319840,"user_tz":-330,"elapsed":4,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}},"outputId":"42b7fe65-f4ea-4234-f1d3-d6150a74b6b7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(455, 30)\n"]}]},{"cell_type":"code","source":["depth = [10,11,12,13,14,15]\n","splits = [2,3,4,5,6]\n","n_f = [26,27,28,29,30]\n","clf = Hyperparameter(max_depth = depth, min_samples_split=splits, n_features=n_f)"],"metadata":{"id":"zhBZswxbD9VG","executionInfo":{"status":"ok","timestamp":1686044371924,"user_tz":-330,"elapsed":557,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["clf.tune(X,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYvgTRatE2Zl","executionInfo":{"status":"ok","timestamp":1686044960343,"user_tz":-330,"elapsed":572660,"user":{"displayName":"Abhinav Tiwari","userId":"15987600730948891294"}},"outputId":"9dfb3607-0417-4cc8-9267-3313e82596e0"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'max_depth': 13, 'min_samples_split': 5, 'n_features': 26},\n"," 0.9736842105263158)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"PBvpDklZE6X1"},"execution_count":null,"outputs":[]}]}